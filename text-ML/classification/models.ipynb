{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3fe6df1",
   "metadata": {},
   "source": [
    "# Text Classification - Dataset Victor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a1d8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages imports\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd78b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data load\n",
    "train = pd.read_csv('./dataset/train_small.csv')\n",
    "test = pd.read_csv('./dataset/test_small.csv')\n",
    "validation = pd.read_csv('./dataset/validation_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355e9460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149217 entries, 0 to 149216\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   themes         149217 non-null  object\n",
      " 1   process_id     149217 non-null  object\n",
      " 2   file_name      149217 non-null  object\n",
      " 3   document_type  149217 non-null  object\n",
      " 4   pages          149217 non-null  int64 \n",
      " 5   body           149217 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 6.8+ MB\n",
      "None\n",
      "['outros' 'sentenca' 'peticao_do_RE' 'despacho_de_admissibilidade'\n",
      " 'acordao_de_2_instancia' 'agravo_em_recurso_extraordinario']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>themes</th>\n",
       "      <th>process_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>document_type</th>\n",
       "      <th>pages</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[232]</td>\n",
       "      <td>AI_856934</td>\n",
       "      <td>AI_856934_1926210_1060_17072013.pdf</td>\n",
       "      <td>outros</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"tribunal justiça estado bahia poder judiciár...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[232]</td>\n",
       "      <td>AI_856934</td>\n",
       "      <td>AI_856934_1926211_34_17072013.pdf</td>\n",
       "      <td>outros</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"excelentíssimo senhor doutor juiz direito ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[232]</td>\n",
       "      <td>AI_856934</td>\n",
       "      <td>AI_856934_1926211_34_17072013.pdf</td>\n",
       "      <td>outros</td>\n",
       "      <td>2</td>\n",
       "      <td>{\"razões recurso inominado recorrente atlantic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[232]</td>\n",
       "      <td>AI_856934</td>\n",
       "      <td>AI_856934_1926211_34_17072013.pdf</td>\n",
       "      <td>outros</td>\n",
       "      <td>3</td>\n",
       "      <td>{\"empresa recorrente tornou credora dos débito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[232]</td>\n",
       "      <td>AI_856934</td>\n",
       "      <td>AI_856934_1926211_34_17072013.pdf</td>\n",
       "      <td>outros</td>\n",
       "      <td>4</td>\n",
       "      <td>{\"entretanto verdade parte apelante tornou tit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  themes process_id                            file_name document_type  pages  \\\n",
       "0  [232]  AI_856934  AI_856934_1926210_1060_17072013.pdf        outros      1   \n",
       "1  [232]  AI_856934    AI_856934_1926211_34_17072013.pdf        outros      1   \n",
       "2  [232]  AI_856934    AI_856934_1926211_34_17072013.pdf        outros      2   \n",
       "3  [232]  AI_856934    AI_856934_1926211_34_17072013.pdf        outros      3   \n",
       "4  [232]  AI_856934    AI_856934_1926211_34_17072013.pdf        outros      4   \n",
       "\n",
       "                                                body  \n",
       "0  {\"tribunal justiça estado bahia poder judiciár...  \n",
       "1  {\"excelentíssimo senhor doutor juiz direito ju...  \n",
       "2  {\"razões recurso inominado recorrente atlantic...  \n",
       "3  {\"empresa recorrente tornou credora dos débito...  \n",
       "4  {\"entretanto verdade parte apelante tornou tit...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick view at the dataset\n",
    "print(train.info())\n",
    "print(train['document_type'].unique())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fe610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data partition\n",
    "X_train = train['body']\n",
    "Y_train = train['document_type']\n",
    "\n",
    "X_valid = validation['body']\n",
    "Y_valid = validation['document_type']\n",
    "\n",
    "X_test = test['body']\n",
    "Y_test = test['document_type']\n",
    "\n",
    "scoring = {\n",
    "    'f1_micro',\n",
    "    'f1_macro',\n",
    "    'f1_weighted'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d386a",
   "metadata": {},
   "source": [
    "## Machine Learning Without Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b720f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters:\n",
      "{'vect__min_df': 3, 'vect__ngram_range': (1, 3), 'vect__smooth_idf': True}\n",
      "Best scorers: \n",
      "0.9130794220352293\n",
      "F1-Score (micro) Validation:  0.9185623053781601\n",
      "F1-Score (micro) Test:  0.9225132424680191\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer + MultinomialNB\n",
    "\n",
    "pipe_tfidf_nb = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "param_tfidf_nb = {\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'vect__smooth_idf': [True],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]\n",
    "}\n",
    "\n",
    "grid_search_tfidf_nb = GridSearchCV(estimator=pipe_tfidf_nb, param_grid=param_tfidf_nb, n_jobs=-1, verbose=10, scoring=scoring, refit='f1_micro')\n",
    "grid_search_tfidf_nb.fit(X_train, Y_train)\n",
    "print(\"Best parameters:\")\n",
    "print(grid_search_tfidf_nb.best_params_)\n",
    "print(\"Best scorers: \") # 0.913\n",
    "print(grid_search_tfidf_nb.best_score_)\n",
    "tfidf_naive = grid_search_tfidf_nb.best_estimator_\n",
    "print('F1-Score (micro) Validation: ', f1_score(Y_valid, tfidf_naive.predict(X_valid), average='micro'))\n",
    "print('F1-Score (micro) Test: ', f1_score(Y_test, tfidf_naive.predict(X_test), average='micro')) # 0.922 - antes 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e3044a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters:\n",
      "{'vect__min_df': 3, 'vect__ngram_range': (1, 3), 'vect__smooth_idf': True}\n",
      "Best scorers: \n",
      "0.9215904678885938\n",
      "F1-Score (micro) Validation:  0.9282102707552646\n",
      "F1-Score (micro) Test:  0.9310449511127861\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer + SDGClassifier\n",
    "\n",
    "pipe_tfidf_sdg = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "param_tfidf_sdg = {\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'vect__smooth_idf': [True],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'f1_micro',\n",
    "    'f1_macro',\n",
    "    'f1_weighted'\n",
    "}\n",
    "\n",
    "grid_search_tfidf_sdg = GridSearchCV(estimator=pipe_tfidf_sdg, param_grid=param_tfidf_sdg, n_jobs=-1, verbose=10, scoring=scoring, refit='f1_micro')\n",
    "grid_search_tfidf_sdg.fit(X_train, Y_train)\n",
    "print(\"Best parameters:\")\n",
    "print(grid_search_tfidf_sdg.best_params_)\n",
    "print(\"Best scorers: \")\n",
    "print(grid_search_tfidf_sdg.best_score_)\n",
    "tfidf_sdg = grid_search_tfidf_sdg.best_estimator_\n",
    "print('F1-Score (micro) Validation: ', f1_score(Y_valid, tfidf_sdg.predict(X_valid), average='micro'))\n",
    "print('F1-Score (micro) Test: ', f1_score(Y_test, tfidf_sdg.predict(X_test), average='micro')) # 0.93 - antes 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70e8878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters:\n",
      "{'vect__max_df': 0.5, 'vect__min_df': 1, 'vect__ngram_range': (1, 3)}\n",
      "Best scorers: \n",
      "0.9160213152849689\n",
      "F1-Score (micro) Validation:  0.9505040375785084\n",
      "F1-Score (micro) Test:  0.9531855201725185\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer + SDGClassifier\n",
    "\n",
    "pipe_countv_sdg = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "param_countv_sdg = {\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vect__max_df': [0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_countv_sdg = GridSearchCV(estimator=pipe_countv_sdg, param_grid=param_countv_sdg, n_jobs=-1, verbose=10, scoring=scoring, refit='f1_micro')\n",
    "grid_search_countv_sdg.fit(X_train, Y_train)\n",
    "print(\"Best parameters:\")\n",
    "print(grid_search_countv_sdg.best_params_)\n",
    "print(\"Best scorers: \")\n",
    "print(grid_search_countv_sdg.best_score_)\n",
    "countv_sdg = grid_search_countv_sdg.best_estimator_\n",
    "print('F1-Score (micro) Validation: ', f1_score(Y_valid, countv_sdg.predict(X_valid), average='micro'))\n",
    "print('F1-Score (micro) Test: ', f1_score(Y_test, countv_sdg.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae1aed4",
   "metadata": {},
   "source": [
    "Logo, obtemos que o modelo com maior acurácia é aquele em que se usa um pipeline de **CountVectorizer(max_df=0.5, min_df=1, ngram_range=(1,3))** e **SDGClassifier()**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef126d",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cf125fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data load\n",
    "train = pd.read_csv('./dataset/train_small.csv')\n",
    "test = pd.read_csv('./dataset/test_small.csv')\n",
    "validation = pd.read_csv('./dataset/validation_small.csv')\n",
    "\n",
    "# Data partition\n",
    "X_train = train['body']\n",
    "Y_train = train['document_type']\n",
    "\n",
    "X_valid = validation['body']\n",
    "Y_valid = validation['document_type']\n",
    "\n",
    "X_test = test['body']\n",
    "Y_test = test['document_type']\n",
    "\n",
    "scoring = {\n",
    "    'f1_micro',\n",
    "    'f1_macro',\n",
    "    'f1_weighted'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cdcc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying GPAM Preprocessing to the datasets\n",
    "from pre_processing import Pipeline\n",
    "\n",
    "for text in X_train:\n",
    "    Pipeline().apply(text)\n",
    "\n",
    "for text in X_test:\n",
    "    Pipeline().apply(text)\n",
    "    \n",
    "for text in X_valid:\n",
    "    Pipeline().apply(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb275e5c",
   "metadata": {},
   "source": [
    "# Machine Learning + PreProcessing (GPAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c0d9fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters:\n",
      "{'vect__min_df': 3, 'vect__ngram_range': (1, 3), 'vect__smooth_idf': True}\n",
      "Best scorers: \n",
      "0.9130794220352293\n",
      "F1-Score (micro) Validation:  0.9185623053781601\n",
      "F1-Score (micro) Test:  0.9225132424680191\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer + MultinomialNB\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "pipe_tfidf_nb = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "param_tfidf_nb = {\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'vect__smooth_idf': [True],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]\n",
    "}\n",
    "\n",
    "grid_search_tfidf_nb = GridSearchCV(estimator=pipe_tfidf_nb, param_grid=param_tfidf_nb, n_jobs=-1, verbose=10, scoring=scoring, refit='f1_micro')\n",
    "grid_search_tfidf_nb.fit(X_train, Y_train)\n",
    "print(\"Best parameters:\")\n",
    "print(grid_search_tfidf_nb.best_params_)\n",
    "print(\"Best scorers: \") # 0.913\n",
    "print(grid_search_tfidf_nb.best_score_)\n",
    "tfidf_naive = grid_search_tfidf_nb.best_estimator_\n",
    "print('F1-Score (micro) Validation: ', f1_score(Y_valid, tfidf_naive.predict(X_valid), average='micro'))\n",
    "print('F1-Score (micro) Test: ', f1_score(Y_test, tfidf_naive.predict(X_test), average='micro')) # 0.922 - antes 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f266b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters:\n",
      "{'vect__min_df': 3, 'vect__ngram_range': (1, 3), 'vect__smooth_idf': True}\n",
      "Best scorers: \n",
      "0.9213827153238074\n",
      "F1-Score (micro) Validation:  0.9281469361904259\n",
      "F1-Score (micro) Test:  0.9310030776961247\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer + SDGClassifier\n",
    "\n",
    "pipe_tfidf_sdg = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "param_tfidf_sdg = {\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'vect__smooth_idf': [True],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'f1_micro',\n",
    "    'f1_macro',\n",
    "    'f1_weighted'\n",
    "}\n",
    "\n",
    "grid_search_tfidf_sdg = GridSearchCV(estimator=pipe_tfidf_sdg, param_grid=param_tfidf_sdg, n_jobs=-1, verbose=10, scoring=scoring, refit='f1_micro')\n",
    "grid_search_tfidf_sdg.fit(X_train, Y_train)\n",
    "print(\"Best parameters:\")\n",
    "print(grid_search_tfidf_sdg.best_params_)\n",
    "print(\"Best scorers: \")\n",
    "print(grid_search_tfidf_sdg.best_score_)\n",
    "tfidf_sdg = grid_search_tfidf_sdg.best_estimator_\n",
    "print('F1-Score (micro) Validation: ', f1_score(Y_valid, tfidf_sdg.predict(X_valid), average='micro'))\n",
    "print('F1-Score (micro) Test: ', f1_score(Y_test, tfidf_sdg.predict(X_test), average='micro')) # 0.93 - antes 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "284f146f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters:\n",
      "{'vect__max_df': 0.5, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Best scorers: \n",
      "0.9156125044840504\n",
      "F1-Score (micro) Validation:  0.9499973610597984\n",
      "F1-Score (micro) Test:  0.9527667860059041\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer + SDGClassifier\n",
    "\n",
    "pipe_countv_sdg = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "param_countv_sdg = {\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vect__max_df': [0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_countv_sdg = GridSearchCV(estimator=pipe_countv_sdg, param_grid=param_countv_sdg, n_jobs=-1, verbose=10, scoring=scoring, refit='f1_micro')\n",
    "grid_search_countv_sdg.fit(X_train, Y_train)\n",
    "print(\"Best parameters:\")\n",
    "print(grid_search_countv_sdg.best_params_)\n",
    "print(\"Best scorers: \")\n",
    "print(grid_search_countv_sdg.best_score_)\n",
    "countv_sdg = grid_search_countv_sdg.best_estimator_\n",
    "print('F1-Score (micro) Validation: ', f1_score(Y_valid, countv_sdg.predict(X_valid), average='micro'))\n",
    "print('F1-Score (micro) Test: ', f1_score(Y_test, countv_sdg.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f91962",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5538b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and text cleaning\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.compile('[{}\"]').sub('', text)\n",
    "    return text\n",
    "\n",
    "X_train.apply(clean_text)\n",
    "X_valid.apply(clean_text)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=50000, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train.values)\n",
    "\n",
    "tokenizer.fit_on_texts(X_valid.values)\n",
    "\n",
    "# New X_train\n",
    "X_train_tok = tokenizer.texts_to_sequences(X_train.values)\n",
    "X_train_tok = pad_sequences(X_train_tok, maxlen=250)\n",
    "\n",
    "# New X_valid\n",
    "X_valid_tok = tokenizer.texts_to_sequences(X_valid.values)\n",
    "X_valid_tok = pad_sequences(X_valid_tok, maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b2cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y separation\n",
    "def to_category(tipo):\n",
    "    if tipo[0] == 'outros':\n",
    "        tipo[0] = 0\n",
    "    elif tipo == 'sentenca':\n",
    "        tipo = 1\n",
    "    elif tipo == 'peticao_do_RE':\n",
    "        tipo = 2\n",
    "    elif tipo == 'despacho_de_admissibilidade':\n",
    "        tipo = 3\n",
    "    elif tipo == 'acordao_de_2_instancia':\n",
    "        tipo = 4\n",
    "    elif tipo == 'agravo_em_recurso_extraordinario':\n",
    "        tipo = 5\n",
    "    return tipo\n",
    "\n",
    "Y_train = pd.get_dummies(Y_train).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54ab910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 5,081,006\n",
      "Trainable params: 5,081,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model creation\n",
    "model = Sequential()\n",
    "model.add(Embedding(50000, 100, input_length=X_train_tok.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73323849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149217, 250)\n",
      "(149217, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tok.shape)\n",
    "print(Y_train_deep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa432b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2099/2099 [==============================] - 2402s 1s/step - loss: 0.2754 - accuracy: 0.9241 - val_loss: 0.4355 - val_accuracy: 0.8963\n",
      "Epoch 2/3\n",
      "2099/2099 [==============================] - 2374s 1s/step - loss: 0.1608 - accuracy: 0.9463 - val_loss: 0.4280 - val_accuracy: 0.8951\n",
      "Epoch 3/3\n",
      "2099/2099 [==============================] - 2424s 1s/step - loss: 0.1197 - accuracy: 0.9577 - val_loss: 0.4507 - val_accuracy: 0.8935\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train_tok, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450a5f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2961/2961 [==============================] - 198s 67ms/step - loss: 0.2241 - accuracy: 0.9390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2241349071264267, 0.9389877319335938]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid = pd.get_dummies(Y_valid).values\n",
    "validation_values = model.evaluate(X_valid_tok,Y_valid)\n",
    "\n",
    "# Loss and Accuracy\n",
    "validation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c17240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
